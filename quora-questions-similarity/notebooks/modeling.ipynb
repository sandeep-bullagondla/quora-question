{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f717c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow import MlflowClient\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92353523",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLFLOW_DIR = \"../mlruns\"\n",
    "MLFLOW_EXP_NAME = \"quora-question-similarity\"\n",
    "mlflow.set_tracking_uri(MLFLOW_DIR)\n",
    "mlflow.set_experiment(MLFLOW_EXP_NAME)\n",
    "mlflow_client = MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "284b6f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = mlflow.search_runs(filter_string=\"metrics.best_cv_score < 1\")\n",
    "best_run_id = runs.loc[runs['metrics.test_auc_score'].idxmin()]['run_id']\n",
    "model = mlflow.sklearn.load_model(\"runs:/\" + best_run_id + \"/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6046d4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROCESSED_DATA_FPATH = \"../data/features.pkl\"\n",
    "MLFLOW_DIR = \"../mlruns\"\n",
    "MLFLOW_EXP_NAME = \"quora-question-similarity\"\n",
    "RANDOM_STATE = 12181006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3d45268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///c:/Users/aksha/Documents/Projects/NLP-Quora/notebooks/../mlruns/313535672057841037', creation_time=1686155617750, experiment_id='313535672057841037', last_update_time=1686155617750, lifecycle_stage='active', name='quora-question-similarity', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(MLFLOW_DIR)\n",
    "mlflow.set_experiment(experiment_name=MLFLOW_EXP_NAME)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e058eeae",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80653caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PREPROCESSED_DATA_FPATH, \"rb\") as f:\n",
    "    features_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "091ff2cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_lemma</th>\n",
       "      <th>q1_lemma_len</th>\n",
       "      <th>q2_lemma</th>\n",
       "      <th>q2_lemma_len</th>\n",
       "      <th>q1_len</th>\n",
       "      <th>...</th>\n",
       "      <th>num_common_words_lemma</th>\n",
       "      <th>bow_euclidean_dist</th>\n",
       "      <th>bow_manhattan_dist</th>\n",
       "      <th>bow_cosine_dist</th>\n",
       "      <th>tfidf_euclidean_dist</th>\n",
       "      <th>tfidf_manhattan_dist</th>\n",
       "      <th>tfidf_cosine_dist</th>\n",
       "      <th>w2v_euclidean_dist</th>\n",
       "      <th>w2v_manhattan_dist</th>\n",
       "      <th>w2v_cosine_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>306013</th>\n",
       "      <td>331721</td>\n",
       "      <td>444565</td>\n",
       "      <td>I'm just over 13 years old and 6 ft tall (184c...</td>\n",
       "      <td>Is 6ft 1 tall for a 13 year old girl?</td>\n",
       "      <td>0</td>\n",
       "      <td>year old ft tall cm normal</td>\n",
       "      <td>6</td>\n",
       "      <td>ft tall year old girl</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.269703</td>\n",
       "      <td>0.693814</td>\n",
       "      <td>1.425547</td>\n",
       "      <td>0.240689</td>\n",
       "      <td>0.349829</td>\n",
       "      <td>0.349829</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267651</th>\n",
       "      <td>262077</td>\n",
       "      <td>330035</td>\n",
       "      <td>How can I meet and make more friends as an int...</td>\n",
       "      <td>How can I make friends if I am an introvert?</td>\n",
       "      <td>1</td>\n",
       "      <td>meet make friend introvert</td>\n",
       "      <td>4</td>\n",
       "      <td>make friend introvert</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.133975</td>\n",
       "      <td>0.582448</td>\n",
       "      <td>0.843075</td>\n",
       "      <td>0.169623</td>\n",
       "      <td>0.045761</td>\n",
       "      <td>0.045761</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119103</th>\n",
       "      <td>61911</td>\n",
       "      <td>61912</td>\n",
       "      <td>If gay marriage is legal, then what's to stop ...</td>\n",
       "      <td>If gay marriage is legal, why isn't polygamy?</td>\n",
       "      <td>1</td>\n",
       "      <td>gay marriage legal stop people want reintroduc...</td>\n",
       "      <td>8</td>\n",
       "      <td>gay marriage legal polygamy</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.292893</td>\n",
       "      <td>0.758390</td>\n",
       "      <td>1.825271</td>\n",
       "      <td>0.287578</td>\n",
       "      <td>0.076995</td>\n",
       "      <td>0.076995</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          qid1    qid2                                          question1  \\\n",
       "306013  331721  444565  I'm just over 13 years old and 6 ft tall (184c...   \n",
       "267651  262077  330035  How can I meet and make more friends as an int...   \n",
       "119103   61911   61912  If gay marriage is legal, then what's to stop ...   \n",
       "\n",
       "                                            question2  is_duplicate  \\\n",
       "306013          Is 6ft 1 tall for a 13 year old girl?             0   \n",
       "267651   How can I make friends if I am an introvert?             1   \n",
       "119103  If gay marriage is legal, why isn't polygamy?             1   \n",
       "\n",
       "                                                 q1_lemma  q1_lemma_len  \\\n",
       "306013                         year old ft tall cm normal             6   \n",
       "267651                         meet make friend introvert             4   \n",
       "119103  gay marriage legal stop people want reintroduc...             8   \n",
       "\n",
       "                           q2_lemma  q2_lemma_len  q1_len  ...  \\\n",
       "306013        ft tall year old girl             5      14  ...   \n",
       "267651        make friend introvert             3      11  ...   \n",
       "119103  gay marriage legal polygamy             4      15  ...   \n",
       "\n",
       "        num_common_words_lemma  bow_euclidean_dist  bow_manhattan_dist  \\\n",
       "306013                       4            1.732051                 3.0   \n",
       "267651                       3            1.000000                 1.0   \n",
       "119103                       4            2.000000                 4.0   \n",
       "\n",
       "        bow_cosine_dist  tfidf_euclidean_dist  tfidf_manhattan_dist  \\\n",
       "306013         0.269703              0.693814              1.425547   \n",
       "267651         0.133975              0.582448              0.843075   \n",
       "119103         0.292893              0.758390              1.825271   \n",
       "\n",
       "        tfidf_cosine_dist  w2v_euclidean_dist  w2v_manhattan_dist  \\\n",
       "306013           0.240689            0.349829            0.349829   \n",
       "267651           0.169623            0.045761            0.045761   \n",
       "119103           0.287578            0.076995            0.076995   \n",
       "\n",
       "        w2v_cosine_dist  \n",
       "306013              0.0  \n",
       "267651              0.0  \n",
       "119103              0.0  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f85dada",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features_df.drop([\"qid1\", \"qid2\", \"question1\", \"question2\", \"q1_lemma\", \"q2_lemma\", \"is_duplicate\"], axis=1)\n",
    "y = features_df[\"is_duplicate\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b4ee243",
   "metadata": {},
   "source": [
    "## Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea94f46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0440613",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02a93a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (283000, 16) (283000,)\n",
      "Train size: (121287, 16) (121287,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train size:\", X_train.shape, y_train.shape)\n",
    "print(\"Train size:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "755a2ad9",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4cd5ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c97a49a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(actual, pred):\n",
    "\n",
    "    accuracy = metrics.accuracy_score(actual, pred)\n",
    "    precision = metrics.precision_score(actual, pred)\n",
    "    recall = metrics.recall_score(actual, pred)\n",
    "    f1_score = metrics.f1_score(actual, pred)\n",
    "    auc_score = metrics.roc_auc_score(actual, pred)\n",
    "    \n",
    "    return accuracy, precision, recall, f1_score, auc_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f00c2437",
   "metadata": {},
   "source": [
    "### Linear models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e31151f0",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "119f85ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ade15066",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/07 22:28:19 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\aksha\\Documents\\Projects\\NLP-Quora\\quora-env\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/06/07 22:30:31 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\aksha\\Documents\\Projects\\NLP-Quora\\quora-env\\lib\\site-packages\\mlflow\\models\\signature.py:144: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/06/07 22:30:37 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\aksha\\Documents\\Projects\\NLP-Quora\\quora-env\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    }
   ],
   "source": [
    "mlflow.sklearn.autolog()\n",
    "with mlflow.start_run(run_name=\"logistic_reg\"):\n",
    "    lr = LogisticRegressionCV(cv=5, class_weight=\"balanced\", max_iter=1000, random_state=RANDOM_STATE)\n",
    "    lr.fit(X_train, y_train)\n",
    "    \n",
    "    y_test_pred = lr.predict(X_test) > 0.5\n",
    "    (accuracy, precision, recall, f1_score, auc_score) = eval_metrics(y_test, y_test_pred)\n",
    "    mlflow.log_metric(\"testAccuracy\", accuracy)\n",
    "    mlflow.log_metric(\"testPrecission\", precision)\n",
    "    mlflow.log_metric(\"testRecall\", recall)\n",
    "    mlflow.log_metric(\"testF1_Score\", f1_score)\n",
    "    mlflow.log_metric(\"testAUC_Score\", auc_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac995e4a",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee312cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9550c5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/07 22:51:08 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\aksha\\Documents\\Projects\\NLP-Quora\\quora-env\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/06/07 22:51:25 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\aksha\\Documents\\Projects\\NLP-Quora\\quora-env\\lib\\site-packages\\mlflow\\models\\signature.py:144: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/06/07 22:51:56 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\aksha\\Documents\\Projects\\NLP-Quora\\quora-env\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/06/07 22:52:23 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\aksha\\Documents\\Projects\\NLP-Quora\\quora-env\\lib\\site-packages\\mlflow\\models\\signature.py:144: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in the last tree is: 113231 with ccp_alpha: 0.08096648553716229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/07 22:52:30 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\aksha\\Documents\\Projects\\NLP-Quora\\quora-env\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/06/07 22:52:56 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\aksha\\Documents\\Projects\\NLP-Quora\\quora-env\\lib\\site-packages\\mlflow\\models\\signature.py:144: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in the last tree is: 113231 with ccp_alpha: 0.08096648553716229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/07 22:53:03 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\aksha\\Documents\\Projects\\NLP-Quora\\quora-env\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/06/07 22:53:30 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\aksha\\Documents\\Projects\\NLP-Quora\\quora-env\\lib\\site-packages\\mlflow\\models\\signature.py:144: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in the last tree is: 113231 with ccp_alpha: 0.08096648553716229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/07 22:53:36 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\aksha\\Documents\\Projects\\NLP-Quora\\quora-env\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/06/07 22:54:02 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\aksha\\Documents\\Projects\\NLP-Quora\\quora-env\\lib\\site-packages\\mlflow\\models\\signature.py:144: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in the last tree is: 113231 with ccp_alpha: 0.08096648553716229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/07 22:54:09 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\aksha\\Documents\\Projects\\NLP-Quora\\quora-env\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/06/07 22:54:35 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\aksha\\Documents\\Projects\\NLP-Quora\\quora-env\\lib\\site-packages\\mlflow\\models\\signature.py:144: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in the last tree is: 113231 with ccp_alpha: 0.08096648553716229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/07 22:54:42 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\aksha\\Documents\\Projects\\NLP-Quora\\quora-env\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/06/07 22:55:09 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\aksha\\Documents\\Projects\\NLP-Quora\\quora-env\\lib\\site-packages\\mlflow\\models\\signature.py:144: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in the last tree is: 113231 with ccp_alpha: 0.08096648553716229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/07 22:55:16 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\aksha\\Documents\\Projects\\NLP-Quora\\quora-env\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/06/07 22:55:43 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\aksha\\Documents\\Projects\\NLP-Quora\\quora-env\\lib\\site-packages\\mlflow\\models\\signature.py:144: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39mfor\u001b[39;00m ccp_alpha \u001b[39min\u001b[39;00m ccp_alphas:\n\u001b[0;32m     17\u001b[0m     clf \u001b[39m=\u001b[39m DecisionTreeClassifier(class_weight\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, random_state\u001b[39m=\u001b[39mRANDOM_STATE)\n\u001b[1;32m---> 18\u001b[0m     clf\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     19\u001b[0m     clfs\u001b[39m.\u001b[39mappend(clf)\n\u001b[0;32m     20\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNumber of nodes in the last tree is: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m with ccp_alpha: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m     21\u001b[0m             clfs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mtree_\u001b[39m.\u001b[39mnode_count, ccp_alphas[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m     22\u001b[0m     )\n\u001b[0;32m     23\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\aksha\\Documents\\Projects\\NLP-Quora\\quora-env\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:554\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    552\u001b[0m     patch_function\u001b[39m.\u001b[39mcall(call_original, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    553\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 554\u001b[0m     patch_function(call_original, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    556\u001b[0m session\u001b[39m.\u001b[39mstate \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msucceeded\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    558\u001b[0m try_log_autologging_event(\n\u001b[0;32m    559\u001b[0m     AutologgingEventLogger\u001b[39m.\u001b[39mget_logger()\u001b[39m.\u001b[39mlog_patch_function_success,\n\u001b[0;32m    560\u001b[0m     session,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    564\u001b[0m     kwargs,\n\u001b[0;32m    565\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\aksha\\Documents\\Projects\\NLP-Quora\\quora-env\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:254\u001b[0m, in \u001b[0;36mwith_managed_run.<locals>.patch_with_managed_run\u001b[1;34m(original, *args, **kwargs)\u001b[0m\n\u001b[0;32m    251\u001b[0m     managed_run \u001b[39m=\u001b[39m create_managed_run()\n\u001b[0;32m    253\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 254\u001b[0m     result \u001b[39m=\u001b[39m patch_function(original, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    255\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mException\u001b[39;00m, \u001b[39mKeyboardInterrupt\u001b[39;00m):\n\u001b[0;32m    256\u001b[0m     \u001b[39m# In addition to standard Python exceptions, handle keyboard interrupts to ensure\u001b[39;00m\n\u001b[0;32m    257\u001b[0m     \u001b[39m# that runs are terminated if a user prematurely interrupts training execution\u001b[39;00m\n\u001b[0;32m    258\u001b[0m     \u001b[39m# (e.g. via sigint / ctrl-c)\u001b[39;00m\n\u001b[0;32m    259\u001b[0m     \u001b[39mif\u001b[39;00m managed_run:\n",
      "File \u001b[1;32mc:\\Users\\aksha\\Documents\\Projects\\NLP-Quora\\quora-env\\lib\\site-packages\\mlflow\\sklearn\\__init__.py:1612\u001b[0m, in \u001b[0;36m_autolog.<locals>.patched_fit\u001b[1;34m(fit_impl, allow_children_patch, original, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1608\u001b[0m \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mshould_log():\n\u001b[0;32m   1609\u001b[0m     \u001b[39m# In `fit_mlflow` call, it will also call metric API for computing training metrics\u001b[39;00m\n\u001b[0;32m   1610\u001b[0m     \u001b[39m# so we need temporarily disable the post_training_metrics patching.\u001b[39;00m\n\u001b[0;32m   1611\u001b[0m     \u001b[39mwith\u001b[39;00m _AUTOLOGGING_METRICS_MANAGER\u001b[39m.\u001b[39mdisable_log_post_training_metrics():\n\u001b[1;32m-> 1612\u001b[0m         result \u001b[39m=\u001b[39m fit_impl(original, \u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1613\u001b[0m     \u001b[39mif\u001b[39;00m should_log_post_training_metrics:\n\u001b[0;32m   1614\u001b[0m         _AUTOLOGGING_METRICS_MANAGER\u001b[39m.\u001b[39mregister_model(\n\u001b[0;32m   1615\u001b[0m             \u001b[39mself\u001b[39m, mlflow\u001b[39m.\u001b[39mactive_run()\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mrun_id\n\u001b[0;32m   1616\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\aksha\\Documents\\Projects\\NLP-Quora\\quora-env\\lib\\site-packages\\mlflow\\sklearn\\__init__.py:1386\u001b[0m, in \u001b[0;36m_autolog.<locals>.fit_mlflow\u001b[1;34m(original, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1384\u001b[0m params_logging_future \u001b[39m=\u001b[39m autologging_client\u001b[39m.\u001b[39mflush(synchronous\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   1385\u001b[0m fit_output \u001b[39m=\u001b[39m original(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m-> 1386\u001b[0m _log_posttraining_metadata(autologging_client, \u001b[39mself\u001b[39;49m, X, y_true, sample_weight)\n\u001b[0;32m   1387\u001b[0m autologging_client\u001b[39m.\u001b[39mflush(synchronous\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   1388\u001b[0m params_logging_future\u001b[39m.\u001b[39mawait_completion()\n",
      "File \u001b[1;32mc:\\Users\\aksha\\Documents\\Projects\\NLP-Quora\\quora-env\\lib\\site-packages\\mlflow\\sklearn\\__init__.py:1518\u001b[0m, in \u001b[0;36m_autolog.<locals>._log_posttraining_metadata\u001b[1;34m(autologging_client, estimator, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1508\u001b[0m     input_example, signature \u001b[39m=\u001b[39m resolve_input_example_and_signature(\n\u001b[0;32m   1509\u001b[0m         get_input_example,\n\u001b[0;32m   1510\u001b[0m         infer_model_signature,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1513\u001b[0m         _logger,\n\u001b[0;32m   1514\u001b[0m     )\n\u001b[0;32m   1515\u001b[0m     registered_model_name \u001b[39m=\u001b[39m get_autologging_config(\n\u001b[0;32m   1516\u001b[0m         FLAVOR_NAME, \u001b[39m\"\u001b[39m\u001b[39mregistered_model_name\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m     )\n\u001b[1;32m-> 1518\u001b[0m     _log_model_with_except_handling(\n\u001b[0;32m   1519\u001b[0m         estimator,\n\u001b[0;32m   1520\u001b[0m         artifact_path\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1521\u001b[0m         signature\u001b[39m=\u001b[39;49msignature,\n\u001b[0;32m   1522\u001b[0m         input_example\u001b[39m=\u001b[39;49minput_example,\n\u001b[0;32m   1523\u001b[0m         serialization_format\u001b[39m=\u001b[39;49mserialization_format,\n\u001b[0;32m   1524\u001b[0m         registered_model_name\u001b[39m=\u001b[39;49mregistered_model_name,\n\u001b[0;32m   1525\u001b[0m     )\n\u001b[0;32m   1527\u001b[0m \u001b[39mif\u001b[39;00m _is_parameter_search_estimator(estimator):\n\u001b[0;32m   1528\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(estimator, \u001b[39m\"\u001b[39m\u001b[39mbest_estimator_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m log_models:\n",
      "File \u001b[1;32mc:\\Users\\aksha\\Documents\\Projects\\NLP-Quora\\quora-env\\lib\\site-packages\\mlflow\\sklearn\\__init__.py:1502\u001b[0m, in \u001b[0;36m_autolog.<locals>._log_posttraining_metadata.<locals>._log_model_with_except_handling\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1500\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_log_model_with_except_handling\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1501\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1502\u001b[0m         \u001b[39mreturn\u001b[39;00m log_model(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1503\u001b[0m     \u001b[39mexcept\u001b[39;00m _SklearnCustomModelPicklingError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1504\u001b[0m         _logger\u001b[39m.\u001b[39mwarning(\u001b[39mstr\u001b[39m(e))\n",
      "File \u001b[1;32mc:\\Users\\aksha\\Documents\\Projects\\NLP-Quora\\quora-env\\lib\\site-packages\\mlflow\\sklearn\\__init__.py:436\u001b[0m, in \u001b[0;36mlog_model\u001b[1;34m(sk_model, artifact_path, conda_env, code_paths, serialization_format, registered_model_name, signature, input_example, await_registration_for, pip_requirements, extra_pip_requirements, pyfunc_predict_fn, metadata)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[39m@format_docstring\u001b[39m(LOG_MODEL_PARAM_DOCS\u001b[39m.\u001b[39mformat(package_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mscikit-learn\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m    340\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog_model\u001b[39m(\n\u001b[0;32m    341\u001b[0m     sk_model,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    353\u001b[0m     metadata\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    354\u001b[0m ):\n\u001b[0;32m    355\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[39m    Log a scikit-learn model as an MLflow artifact for the current run. Produces an MLflow Model\u001b[39;00m\n\u001b[0;32m    357\u001b[0m \u001b[39m    containing the following flavors:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    434\u001b[0m \n\u001b[0;32m    435\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 436\u001b[0m     \u001b[39mreturn\u001b[39;00m Model\u001b[39m.\u001b[39;49mlog(\n\u001b[0;32m    437\u001b[0m         artifact_path\u001b[39m=\u001b[39;49martifact_path,\n\u001b[0;32m    438\u001b[0m         flavor\u001b[39m=\u001b[39;49mmlflow\u001b[39m.\u001b[39;49msklearn,\n\u001b[0;32m    439\u001b[0m         sk_model\u001b[39m=\u001b[39;49msk_model,\n\u001b[0;32m    440\u001b[0m         conda_env\u001b[39m=\u001b[39;49mconda_env,\n\u001b[0;32m    441\u001b[0m         code_paths\u001b[39m=\u001b[39;49mcode_paths,\n\u001b[0;32m    442\u001b[0m         serialization_format\u001b[39m=\u001b[39;49mserialization_format,\n\u001b[0;32m    443\u001b[0m         registered_model_name\u001b[39m=\u001b[39;49mregistered_model_name,\n\u001b[0;32m    444\u001b[0m         signature\u001b[39m=\u001b[39;49msignature,\n\u001b[0;32m    445\u001b[0m         input_example\u001b[39m=\u001b[39;49minput_example,\n\u001b[0;32m    446\u001b[0m         await_registration_for\u001b[39m=\u001b[39;49mawait_registration_for,\n\u001b[0;32m    447\u001b[0m         pip_requirements\u001b[39m=\u001b[39;49mpip_requirements,\n\u001b[0;32m    448\u001b[0m         extra_pip_requirements\u001b[39m=\u001b[39;49mextra_pip_requirements,\n\u001b[0;32m    449\u001b[0m         pyfunc_predict_fn\u001b[39m=\u001b[39;49mpyfunc_predict_fn,\n\u001b[0;32m    450\u001b[0m         metadata\u001b[39m=\u001b[39;49mmetadata,\n\u001b[0;32m    451\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\aksha\\Documents\\Projects\\NLP-Quora\\quora-env\\lib\\site-packages\\mlflow\\models\\model.py:562\u001b[0m, in \u001b[0;36mModel.log\u001b[1;34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, **kwargs)\u001b[0m\n\u001b[0;32m    560\u001b[0m run_id \u001b[39m=\u001b[39m mlflow\u001b[39m.\u001b[39mtracking\u001b[39m.\u001b[39mfluent\u001b[39m.\u001b[39m_get_or_start_run()\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mrun_id\n\u001b[0;32m    561\u001b[0m mlflow_model \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(artifact_path\u001b[39m=\u001b[39martifact_path, run_id\u001b[39m=\u001b[39mrun_id, metadata\u001b[39m=\u001b[39mmetadata)\n\u001b[1;32m--> 562\u001b[0m flavor\u001b[39m.\u001b[39msave_model(path\u001b[39m=\u001b[39mlocal_path, mlflow_model\u001b[39m=\u001b[39mmlflow_model, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    563\u001b[0m mlflow\u001b[39m.\u001b[39mtracking\u001b[39m.\u001b[39mfluent\u001b[39m.\u001b[39mlog_artifacts(local_path, mlflow_model\u001b[39m.\u001b[39martifact_path)\n\u001b[0;32m    564\u001b[0m tracking_uri \u001b[39m=\u001b[39m _resolve_tracking_uri()\n",
      "File \u001b[1;32mc:\\Users\\aksha\\Documents\\Projects\\NLP-Quora\\quora-env\\lib\\site-packages\\mlflow\\sklearn\\__init__.py:310\u001b[0m, in \u001b[0;36msave_model\u001b[1;34m(sk_model, path, conda_env, code_paths, mlflow_model, serialization_format, signature, input_example, pip_requirements, extra_pip_requirements, pyfunc_predict_fn, metadata)\u001b[0m\n\u001b[0;32m    307\u001b[0m     default_reqs \u001b[39m=\u001b[39m get_default_pip_requirements(include_cloudpickle)\n\u001b[0;32m    308\u001b[0m     \u001b[39m# To ensure `_load_pyfunc` can successfully load the model during the dependency\u001b[39;00m\n\u001b[0;32m    309\u001b[0m     \u001b[39m# inference, `mlflow_model.save` must be called beforehand to save an MLmodel file.\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     inferred_reqs \u001b[39m=\u001b[39m mlflow\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49minfer_pip_requirements(\n\u001b[0;32m    311\u001b[0m         model_data_path,\n\u001b[0;32m    312\u001b[0m         FLAVOR_NAME,\n\u001b[0;32m    313\u001b[0m         fallback\u001b[39m=\u001b[39;49mdefault_reqs,\n\u001b[0;32m    314\u001b[0m     )\n\u001b[0;32m    315\u001b[0m     default_reqs \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(\u001b[39mset\u001b[39m(inferred_reqs)\u001b[39m.\u001b[39munion(default_reqs))\n\u001b[0;32m    316\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\aksha\\Documents\\Projects\\NLP-Quora\\quora-env\\lib\\site-packages\\mlflow\\utils\\environment.py:390\u001b[0m, in \u001b[0;36minfer_pip_requirements\u001b[1;34m(model_uri, flavor, fallback)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[39mInfers the pip requirements of the specified model by creating a subprocess and loading\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[39mthe model in it to determine which packages are imported.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39m:return: A list of inferred pip requirements (e.g. ``[\"scikit-learn==0.24.2\", ...]``).\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    389\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 390\u001b[0m     \u001b[39mreturn\u001b[39;00m _infer_requirements(model_uri, flavor)\n\u001b[0;32m    391\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    392\u001b[0m     \u001b[39mif\u001b[39;00m fallback \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\aksha\\Documents\\Projects\\NLP-Quora\\quora-env\\lib\\site-packages\\mlflow\\utils\\requirements_utils.py:403\u001b[0m, in \u001b[0;36m_infer_requirements\u001b[1;34m(model_uri, flavor)\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[39mif\u001b[39;00m _PYPI_PACKAGE_INDEX \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    401\u001b[0m     _PYPI_PACKAGE_INDEX \u001b[39m=\u001b[39m _load_pypi_package_index()\n\u001b[1;32m--> 403\u001b[0m modules \u001b[39m=\u001b[39m _capture_imported_modules(model_uri, flavor)\n\u001b[0;32m    404\u001b[0m packages \u001b[39m=\u001b[39m _flatten([_MODULES_TO_PACKAGES\u001b[39m.\u001b[39mget(module, []) \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m modules])\n\u001b[0;32m    405\u001b[0m packages \u001b[39m=\u001b[39m \u001b[39mmap\u001b[39m(_normalize_package_name, packages)\n",
      "File \u001b[1;32mc:\\Users\\aksha\\Documents\\Projects\\NLP-Quora\\quora-env\\lib\\site-packages\\mlflow\\utils\\requirements_utils.py:305\u001b[0m, in \u001b[0;36m_capture_imported_modules\u001b[1;34m(model_uri, flavor)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[39m# Lazily import `_capture_module` here to avoid circular imports.\u001b[39;00m\n\u001b[0;32m    303\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmlflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m _capture_modules\n\u001b[1;32m--> 305\u001b[0m _run_command(\n\u001b[0;32m    306\u001b[0m     [\n\u001b[0;32m    307\u001b[0m         sys\u001b[39m.\u001b[39;49mexecutable,\n\u001b[0;32m    308\u001b[0m         _capture_modules\u001b[39m.\u001b[39;49m\u001b[39m__file__\u001b[39;49m,\n\u001b[0;32m    309\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m--model-path\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    310\u001b[0m         local_model_path,\n\u001b[0;32m    311\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m--flavor\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    312\u001b[0m         flavor,\n\u001b[0;32m    313\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m--output-file\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    314\u001b[0m         output_file,\n\u001b[0;32m    315\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m--sys-path\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    316\u001b[0m         json\u001b[39m.\u001b[39;49mdumps(sys\u001b[39m.\u001b[39;49mpath),\n\u001b[0;32m    317\u001b[0m     ],\n\u001b[0;32m    318\u001b[0m     timeout_seconds\u001b[39m=\u001b[39;49mprocess_timeout,\n\u001b[0;32m    319\u001b[0m     env\u001b[39m=\u001b[39;49mmain_env,\n\u001b[0;32m    320\u001b[0m )\n\u001b[0;32m    322\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(output_file) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m    323\u001b[0m     \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39mread()\u001b[39m.\u001b[39msplitlines()\n",
      "File \u001b[1;32mc:\\Users\\aksha\\Documents\\Projects\\NLP-Quora\\quora-env\\lib\\site-packages\\mlflow\\utils\\requirements_utils.py:201\u001b[0m, in \u001b[0;36m_run_command\u001b[1;34m(cmd, timeout_seconds, env)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m     timer\u001b[39m.\u001b[39mstart()\n\u001b[1;32m--> 201\u001b[0m     stdout, stderr \u001b[39m=\u001b[39m proc\u001b[39m.\u001b[39;49mcommunicate()\n\u001b[0;32m    202\u001b[0m     stdout \u001b[39m=\u001b[39m stdout\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    203\u001b[0m     stderr \u001b[39m=\u001b[39m stderr\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\subprocess.py:1134\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[1;34m(self, input, timeout)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     endtime \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1134\u001b[0m     stdout, stderr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_communicate(\u001b[39minput\u001b[39;49m, endtime, timeout)\n\u001b[0;32m   1135\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1136\u001b[0m     \u001b[39m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m     \u001b[39m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\subprocess.py:1508\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[1;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[0;32m   1504\u001b[0m \u001b[39m# Wait for the reader threads, or time out.  If we time out, the\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[39m# threads remain reading and the fds left open in case the user\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m \u001b[39m# calls communicate again.\u001b[39;00m\n\u001b[0;32m   1507\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1508\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstdout_thread\u001b[39m.\u001b[39;49mjoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_remaining_time(endtime))\n\u001b[0;32m   1509\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout_thread\u001b[39m.\u001b[39mis_alive():\n\u001b[0;32m   1510\u001b[0m         \u001b[39mraise\u001b[39;00m TimeoutExpired(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, orig_timeout)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\threading.py:1053\u001b[0m, in \u001b[0;36mThread.join\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1050\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot join current thread\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1052\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1053\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait_for_tstate_lock()\n\u001b[0;32m   1054\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1055\u001b[0m     \u001b[39m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m     \u001b[39m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[0;32m   1057\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(timeout, \u001b[39m0\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\threading.py:1069\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1067\u001b[0m \u001b[39mif\u001b[39;00m lock \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# already determined that the C code is done\u001b[39;00m\n\u001b[0;32m   1068\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_stopped\n\u001b[1;32m-> 1069\u001b[0m \u001b[39melif\u001b[39;00m lock\u001b[39m.\u001b[39;49macquire(block, timeout):\n\u001b[0;32m   1070\u001b[0m     lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m   1071\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mlflow.sklearn.autolog()\n",
    "with mlflow.start_run(run_name=\"decision_tree\"):\n",
    "    dt = DecisionTreeClassifier(class_weight=\"balanced\", random_state=RANDOM_STATE)\n",
    "\n",
    "    params = {\n",
    "        criterion = ['gini', 'entropy'],\n",
    "        max_depth = [2,4,6,8,10,12]\n",
    "    }\n",
    "    dt_grid_cv = GridSearchCV(pipe, parameters)\n",
    "    dt_grid_cv.fit(X_train, y_train)\n",
    "    \n",
    "    y_test_pred = lr.predict(X_test) > 0.5\n",
    "    (accuracy, precision, recall, f1_score, auc_score) = eval_metrics(y_test, y_test_pred)\n",
    "    mlflow.log_metric(\"testAccuracy\", accuracy)\n",
    "    mlflow.log_metric(\"testPrecission\", precision)\n",
    "    mlflow.log_metric(\"testRecall\", recall)\n",
    "    mlflow.log_metric(\"testF1_Score\", f1_score)\n",
    "    mlflow.log_metric(\"testAUC_Score\", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb281dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00, -9.48676901e-20, -1.18584613e-20, ...,\n",
       "        6.80379714e-03,  1.50463223e-02,  8.09664855e-02])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccp_alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42a8b0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0, 5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bc5fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
